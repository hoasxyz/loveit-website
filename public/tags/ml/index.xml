<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on hoas&#39; blog | One Stupid Boy</title>
    <link>/tags/ml/</link>
    <description>Recent content in ML on hoas&#39; blog | One Stupid Boy</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sun, 05 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Genetic Algorithm</title>
      <link>/2019/05/2019-05-05-genetic-algorithm/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/2019-05-05-genetic-algorithm/</guid>
      <description>&lt;h1 id=&#34;genetic-algorithm&#34;&gt;Genetic algorithm&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;遗传算法&lt;/strong&gt;（Genetic Algorithm, GA）起源于对生物系统所进行的计算机模拟研究。它是模仿自然界生物进化机制发展起来的随机全局搜索和优化方法，借鉴了达尔文的进化论和孟德尔的遗传学说。其本质是一种高效、并行、全局搜索的方法，能在搜索过程中自动获取和积累有关搜索空间的知识，并自适应地控制搜索过程以求得最佳解。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;遗传算法的多变异性和遗传算子的设计能够有效时遗传算法跳出局部解而找到全局最佳解，并且合适的遗传算子选择设计能够缩短算法运行时间，使算法更加有效&lt;/strong&gt;。遗传算法的局限性也相当明显，遗传算法最大的局限就在于算法自身的编码，对于一些问题来说遗传算法的编码过程很复杂，而且遗传算子的设计也是必须要参考到很多现实问题因素。R语言有遗传算法的包，一共两个。一个包叫作&lt;strong&gt;mcga&lt;/strong&gt;包；另一个包叫做&lt;strong&gt;genalg&lt;/strong&gt;包，下面我们分别使用两个包来求解。&lt;/p&gt;

&lt;p&gt;一个非常有趣的故事：&lt;a href=&#34;https://songshuhui.net/archives/10462&#34;&gt;内存中的进化&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;基因型(genotype)：性状染色体的内部表现；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;表现型(phenotype)：染色体决定的性状的外部表现，或者说，根据基因型形成的个体的外部表现；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;进化(evolution)：种群逐渐适应生存环境，品质不断得到改良。生物的进化是以种群的形式进行的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;适应度(fitness)：度量某个物种对于生存环境的适应程度。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;选择(selection)：以一定的概率从种群中选择若干个个体。一般，选择过程是一种基于适应度的优胜劣汰的过程。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;复制(reproduction)：细胞分裂时，遗传物质DNA通过复制而转移到新产生的细胞中，新细胞就继承了旧细胞的基因。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;交叉(crossover)：两个染色体的某一相同位置处DNA被切断，前后两串分别交叉组合形成两个新的染色体。也称基因重组或杂交；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;变异(mutation)：复制时可能（很小的概率）产生某些复制差错，变异产生新的染色体，表现出新的性状。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;编码(coding)：DNA中遗传信息在一个长链上按一定的模式排列。遗传编码可看作从表现型到基因型的映射。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;解码(decoding)：基因型到表现型的映射。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;个体(individual)：指染色体带有特征的实体；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;种群(population)：个体的集合，该集合内个体数称为种群的大小。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;遗传算法中每一条染色体，对应着遗传算法的一个解决方案，一般我们用&lt;strong&gt;适应性函数&lt;/strong&gt;（fitness function）来衡量这个解决方案的优劣。所以从一个基因组到其解的适应度形成一个映射。可以把遗传算法的过程看作是一个在多元函数里面求最优解的过程。可以这样想象，这个多维曲面里面有数不清的“山峰”，而这些山峰所对应的就是局部最优解。而其中也会有一个“山峰”的海拔最高的，那么这个就是全局最优解。而遗传算法的任务就是尽量爬到最高峰，而不是陷落在一些小山峰。（另外，值得注意的是遗传算法不一定要找“最高的山峰”，如果问题的适应度评价越小越好的话，那么全局最优解就是函数的最小值，对应的，遗传算法所要找的就是“最深的谷底”。）&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;不管袋鼠的黑白肥瘦高矮、不管它们喜欢吃什么食物，&lt;a href=&#34;https://blog.csdn.net/u010451580/article/details/51178225&#34;&gt;我们&lt;/a&gt;由始至终都只关心一件事情：&lt;strong&gt;袋鼠在哪里&lt;/strong&gt;？&lt;/p&gt;

&lt;p&gt;把那些总是原地踏步和爱走下坡路的袋鼠射杀，这就是遗传算法的精粹！&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Decision Trees and Rules</title>
      <link>/2019/05/2019-05-04-decision-trees-and-rules/</link>
      <pubDate>Sat, 04 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/2019-05-04-decision-trees-and-rules/</guid>
      <description>&lt;h1 id=&#34;decision-trees&#34;&gt;Decision trees&lt;/h1&gt;

&lt;p&gt;第三章依旧是分类，依旧很强大。&lt;strong&gt;决策树&lt;/strong&gt;（decision trees）利用&lt;strong&gt;树形结构&lt;/strong&gt;（tree structure）对特征和潜在结果之间的关系建立模型。比如要考虑工作机会从&lt;strong&gt;根节点&lt;/strong&gt;（root nodes）开始，然后遍历&lt;strong&gt;决策节点&lt;/strong&gt;（decision nodes），决策节点要求基于工作的属性做出选择，，这些选择通过用只是决策潜在结果的&lt;strong&gt;分枝&lt;/strong&gt;（branches）来划分数据，可以用结果yes或no来描述。尽管在默写案例中，可能不只两种结果，在这种情况下，可以做出最终的决策，决策树在&lt;strong&gt;叶节点&lt;/strong&gt;（leaf note, 也称终端节点）终止，业绩点表示因一系列决策而采取的行动。对于预测模型，叶节点提供了决策树中给定系列事件的预期结果。&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;/post/!image/decision_trees.png&#34; alt=&#34;decision trees&#34;&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;divide-and-conquer&#34;&gt;Divide and conquer&lt;/h2&gt;

&lt;p&gt;决策树的建立采用一种称为&lt;strong&gt;递归划分&lt;/strong&gt;（recursive partitioning）的探索法。这种方法也通常称为分而治之（divide and conquer），因为它将数据分解为子集，然后反复分解成更小的子集，以此类推，直到当算法决定数据内的子集足够均匀或者另一种停止准则已经满足是，该过程才停止。&lt;/p&gt;

&lt;p&gt;假设你受雇于好莱坞电影制片厂，拥有可以邀请到许多一线明星的能力。因为业务繁忙你的桌上常常堆放着一沓剧本。你决定研究一个决策树算法来预测一部有潜力的电影是否会落入：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Critical Success&lt;/li&gt;
&lt;li&gt;Mainstream Hit&lt;/li&gt;
&lt;li&gt;Box Office Bust&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;/post/!image/estimate_buget.png&#34; alt=&#34;estimate buget&#34;&gt;
&lt;/center&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Particle Swarm Optimization, PSO</title>
      <link>/2019/05/2019-05-03-particle-swarm-optimization-pso/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/2019-05-03-particle-swarm-optimization-pso/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;“Bees don’t swarm in a mango grove for nothing. Where can you see a wisp of smoke without a fire?”&lt;/p&gt;

&lt;p&gt;– Hla Stavhana&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;pso&#34;&gt;PSO&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;粒子群优化&lt;/strong&gt;（&lt;strong&gt;Particle Swarm Optimization&lt;/strong&gt;, &lt;strong&gt;PSO&lt;/strong&gt;），又称&lt;strong&gt;微粒群算法&lt;/strong&gt;，是由J. Kennedy和R. C. Eberhart等于1995年开发的一种演化计算技术，来源于对一个简化社会模型的模拟。其中“群（swarm）”来源于微粒群匹配M. M. Millonas在开发应用于&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%94%9F%E5%91%BD&#34;&gt;人工生命&lt;/a&gt;（artificial life）的模型时所提出的群体智能的5个基本原则。“粒子（particle）”是一个折衷的选择，因为既需要将群体中的成员描述为没有质量、没有体积的，同时也需要描述它的速度和加速状态。&lt;/p&gt;

&lt;p&gt;PSO算法最初是为了图形化的模拟鸟群优美而不可预测的运动。而通过对动物社会行为的观察，发现在群体中对信息的社会共享提供一个演化的优势，并以此作为开发算法的基础。通过加入近邻的速度匹配、并考虑了多维搜索和根据距离的加速，形成了PSO的最初版本。之后引入了惯性权重*w*来更好的控制开发（exploitation）和探索（exploration），形成了标准版本。&lt;/p&gt;

&lt;p&gt;PSO算法采用实数求解，不要求目标函数可微，而且模型参数的数量还行，原理有趣，易于实现，可以解决大规模、非线性、不可微和多峰值的复杂优化问题。该算法和其它全局优化算法一样可能陷入局部最优，后期收敛速度较慢，但是这个算法的思想还是很有意思的，非常值得学习。&lt;/p&gt;

&lt;h2 id=&#34;principle&#34;&gt;Principle&lt;/h2&gt;

&lt;p&gt;鸟群的运动给了J. Kennedy和R. C. Eberhart灵感。假设每只鸟的基本情况都是一样的，包括飞行速度（含区间）的调整、好的区域的趋向性以及经验和学习能力。它们唯一不同的地方就在于一开始在D维空间中分布的情况不同，因此可以简化为没有体积的“粒子”，在搜索空间中以一定的速度飞行，这个速度根据它本身的飞行经验和同伴的飞行经验来动态调整。第i个微粒表示为&lt;code&gt;Xi = （xi1, xi2, ..., xiD）&lt;/code&gt;，它经历过的最好位置（有最好的适应值）记为&lt;code&gt;Pi = （pi1, pi2, ..., piD）&lt;/code&gt;，也称为&lt;code&gt;pbest&lt;/code&gt;。在群体所有微粒经历过的最好位置的索引号用符号g表示，即Pg，也称为&lt;code&gt;gbest&lt;/code&gt;。微粒i的速度用&lt;code&gt;Vi = （vi1, vi2, ..., viD）&lt;/code&gt;表示。对每一代，它的第d+1维（1 ≤ d+1 ≤ D）根据如下方程进行变化：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;       vid+1 = w∙vid+c1∙rand()∙(pid-xid)+c2∙Rand()∙(pgd-xid)  
       xid+1 = xid+vid				                        &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Naive Bayes</title>
      <link>/2019/05/2019-05-02-naive-bayes/</link>
      <pubDate>Thu, 02 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/2019-05-02-naive-bayes/</guid>
      <description>&lt;h1 id=&#34;bayes-theorem&#34;&gt;Bayes’ theorem&lt;/h1&gt;

&lt;p&gt;这是一种和天气预报大致相同的概念方法。托马斯·贝叶斯（Thomas Bayes）发明了用来描述时间的概率以及如何根据附加信息修正概率的基本原则，这些原则构成了现在称为的&lt;strong&gt;贝叶斯方法&lt;/strong&gt;（Bayesian methods）的基础。&lt;/p&gt;

&lt;p&gt;基于贝叶斯方法的分类器是利用训练数据并根据特征取值提供的证据来计算每一个结果被观察到的概率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;独立事件&lt;/strong&gt;（independent event）同时发生的概率等于它们各自概率的乘积，但是&lt;strong&gt;相关事件&lt;/strong&gt;（dependent event）却没有这么简单。相关事件之间的关系可以用贝叶斯定理（Bayes’ theorem）来描述。如下式，&lt;strong&gt;条件概率&lt;/strong&gt;（conditional probability）：
$$
p(A|B)=\frac{P(A\bigcap B)}{P(B)}=\frac{P(B|A)P(A)}{P(B)}
$$
&lt;center&gt;
&lt;img src=&#34;/post/!image/Bayes1.jpg&#34; alt=&#34;Bayes&#39; theorem&#34;&gt;
&lt;/center&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>k-NN</title>
      <link>/2019/04/2019-04-30-k-nearest-neighbor/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/2019-04-30-k-nearest-neighbor/</guid>
      <description>&lt;h1 id=&#34;machine-learning&#34;&gt;Machine Learning&lt;/h1&gt;

&lt;p&gt;如果机器能够获取经验并且能够利用它们，在以后的类似经验中能够提高它的表现，这就称为&lt;strong&gt;机器学习&lt;/strong&gt;。机器学习是使用数据对模型进行训练，让它针对某种性能指标形成决策。&lt;/p&gt;

&lt;p&gt;机器学习的研究领域是发明计算机算法，把数据转化为智能行动。是&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&#34;&gt;人工智能&lt;/a&gt;的一个分支。人工智能的研究历史有着一条从以“&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E6%8E%A8%E7%90%86&#34;&gt;推理&lt;/a&gt;”为重点，到以“&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%9F%A5%E8%AF%86&#34;&gt;知识&lt;/a&gt;”为重点，再到以“&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%AD%A6%E4%B9%A0&#34;&gt;学习&lt;/a&gt;”为重点的自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习是许多学科的综合，更是这些综合的代名词，目前尚未出现机器学习的准确定义。&lt;/p&gt;

&lt;p&gt;计算机利用&lt;strong&gt;模型&lt;/strong&gt;来概括存储的原始数据。&lt;strong&gt;数据存储&lt;/strong&gt;更偏向记忆存储，利用观测值和提供&lt;strong&gt;推理&lt;/strong&gt;的依据。&lt;/p&gt;

&lt;p&gt;用模型来拟合数据集的过程称为&lt;strong&gt;训练&lt;/strong&gt;。当模型被训练后，数据就转换为一中汇总了原始信息的抽象形式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;预测模型&lt;/strong&gt;是指利用数据集中的其他数值来预测另一个值，&lt;strong&gt;有监督学习&lt;/strong&gt;是指训练一个预测模型的过程。监督说白了就是给出一组数据，有监督学习算法尝试最优化一个函数（模型）来找出属性值之间的组合方式，最终据此给出目标值。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;常见的有监督学习任务是预测案例属于哪一个类别，称为&lt;strong&gt;分类&lt;/strong&gt;。在分类中，被预测的目标特征是一个称为&lt;strong&gt;类&lt;/strong&gt;（class，近似R中的factor）的分类特征，他可以被分为不同的类别，这些类别称为&lt;strong&gt;水平&lt;/strong&gt;（level，近似R中的level）。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;除此之外有监督学习算法还可以预测数值数据，称为&lt;strong&gt;数值预测模型&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;描述性模型&lt;/strong&gt;通过新而有趣的方式总结数据并获得洞察，学习任务从这些洞察中获益。因为描述性模型没有学习目标，所以训练该类模型称为&lt;strong&gt;无监督学习&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;称为&lt;strong&gt;模式发现&lt;/strong&gt;的描述性模型任务用来识别数据之间联系的紧密性。比如模式发现对零售商的交易购买数据进行&lt;strong&gt;购物篮分析&lt;/strong&gt;，用来改进商场销售策略。&lt;/li&gt;
&lt;li&gt;描述性模型中把数据集按照类型分组的任务称为&lt;strong&gt;聚类&lt;/strong&gt;。有时候用作&lt;strong&gt;细分分析&lt;/strong&gt;，即识别具有类似行为或者人口统计信息的人群，使得广告活动能够针对目标受众。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后，&lt;strong&gt;元学习&lt;/strong&gt;（meta-learner）的机器学习算法不与具体学习任务相关联，而是专注于学习如何更有效。元学习算法应用于某些学习的结果来指示其它的学习。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>